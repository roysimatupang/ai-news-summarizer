{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GroqLLM' from 'groq' (D:\\Users\\roysim\\AppData\\Roaming\\Python\\Python311\\site-packages\\groq\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroqLLM\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize Groq LLM\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GroqLLM' from 'groq' (D:\\Users\\roysim\\AppData\\Roaming\\Python\\Python311\\site-packages\\groq\\__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Initialize Groq LLM\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=\"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\",\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "# Custom Agents\n",
    "class NewsCrawlerAgent(Agent):\n",
    "    def execute(self, query):\n",
    "        \"\"\"Fetch news from NewsAPI\"\"\"\n",
    "        api_key = os.getenv(\"eb7606b35e384f1ea2d83225d7a69688\")\n",
    "        url = f\"https://newsapi.org/v2/everything?q={query}&apiKey={api_key}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"articles\"]\n",
    "        else:\n",
    "            return {\"error\": \"Failed to fetch news\"}\n",
    "\n",
    "class NewsAnalystAgent(Agent):\n",
    "    def execute(self, articles):\n",
    "        \"\"\"Analyze news articles for sentiment and categorization\"\"\"\n",
    "        analyzed = []\n",
    "        for article in articles:\n",
    "            sentiment = llm.generate(f\"Analyze the sentiment of this text: {article['description']}\")\n",
    "            categories = llm.generate(f\"Categorize this news article: {article['description']}\")\n",
    "            analyzed.append({\"title\": article[\"title\"], \"sentiment\": sentiment, \"categories\": categories})\n",
    "        return analyzed\n",
    "\n",
    "class NewsSummarizerAgent(Agent):\n",
    "    def execute(self, analyzed_articles):\n",
    "        \"\"\"Summarize the analyzed articles\"\"\"\n",
    "        summaries = []\n",
    "        for article in analyzed_articles:\n",
    "            summary = llm.generate(f\"Summarize this article: {article['title']} - {article['sentiment']} - {article['categories']}\")\n",
    "            summaries.append({\"title\": article[\"title\"], \"summary\": summary})\n",
    "        return summaries\n",
    "\n",
    "# Tasks and Crew\n",
    "class NewsSummarizationApp:\n",
    "    def __init__(self):\n",
    "        self.crawler_agent = NewsCrawlerAgent(\n",
    "            role=\"News Crawler\",\n",
    "            goal=\"Fetch news articles based on a query.\",\n",
    "            verbose=False\n",
    "        )\n",
    "        self.analyst_agent = NewsAnalystAgent(\n",
    "            role=\"News Analyst\",\n",
    "            goal=\"Analyze sentiment and categorize news articles.\",\n",
    "            verbose=False\n",
    "        )\n",
    "        self.summarizer_agent = NewsSummarizerAgent(\n",
    "            role=\"News Summarizer\",\n",
    "            goal=\"Summarize analyzed news articles.\",\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "    def run(self, query):\n",
    "        if not query:\n",
    "            return \"No query provided.\"\n",
    "\n",
    "        task_define_problem = Task(\n",
    "            description=f\"Fetch news articles about {query}\",\n",
    "            agent=self.crawler_agent,\n",
    "            expected_output=\"A list of news articles relevant to the query.\"\n",
    "        )\n",
    "\n",
    "        task_analyze_articles = Task(\n",
    "            description=\"Analyze the fetched news articles for sentiment and categories.\",\n",
    "            agent=self.analyst_agent,\n",
    "            expected_output=\"Analyzed articles with sentiment and categories.\"\n",
    "        )\n",
    "\n",
    "        task_summarize_articles = Task(\n",
    "            description=\"Summarize the analyzed articles.\",\n",
    "            agent=self.summarizer_agent,\n",
    "            expected_output=\"Summaries of the analyzed news articles.\"\n",
    "        )\n",
    "\n",
    "        crew = Crew(\n",
    "            agents=[self.crawler_agent, self.analyst_agent, self.summarizer_agent],\n",
    "            tasks=[task_define_problem, task_analyze_articles, task_summarize_articles],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        result = crew.kickoff()\n",
    "        return result\n",
    "\n",
    "# Streamlit App\n",
    "st.title(\"AI-Powered News Summarizer\")\n",
    "app = NewsSummarizationApp()\n",
    "query = st.text_input(\"Enter a topic to search for news:\")\n",
    "if query:\n",
    "    st.write(f\"Fetching news for: {query}\")\n",
    "    result = app.run(query)\n",
    "    st.write(\"## Results\")\n",
    "    st.write(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'groq.llms'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcrewai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Agent,Task, Crew, Process\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgroq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GroqLLM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'groq.llms'"
     ]
    }
   ],
   "source": [
    "from crewai import Agent,Task, Crew, Process\n",
    "from groq.llms import GroqLLM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
